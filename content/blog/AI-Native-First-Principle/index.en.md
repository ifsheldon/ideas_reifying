+++
title = "Draft: Nativeness and First Principle of AI"
description = "TL;DR: Multi-modal intelligence is the key"
draft = false

weight = 3

[taxonomies]
tags = ["AI", "AR"]

[extra]
feature_image = "kokichi_muta.png"
feature = true
+++

## A bit of detour

Apologies if the dark-themed cover startled you. It features a character, Kokichi Muta, from *Jujutsu Kaisen* that I watched in 2023.

![Kokichi Muta](./kokichi_muta.png)
> Mechamaru, or its puppeteer—Kokichi Muta

His backstory doesn't matter here. What's relevant to this blog are his curse and his talent. His curse is a fragile body, but as the saying goes, "When God closes a door, he opens a window." his talent lies in "mechanical manipulation" and his exceptional strategic mind.

As GPT-4 emerged and I interacted with it more in daily life, research, and work, my vague impressions of it became more and more clearer until the image above popped up in my mind from nowhere, along with Mechamaru and Kokichi Muta. If you're particularly familiar with GPT-4 and also know *Jujutsu
Kaisen*, you might find this interesting.
However, the intersection of people familiar with both is, after all, a minority, so I digress a bit here.

> If you want to know more about Kokichi Muta, you can check [here](https://zh.moegirl.org.cn/zh-hans/究极机械丸/与幸吉) or [here](https://jujutsu-kaisen.fandom.com/wiki/Kokichi_Muta).

> If you're also a fan of *Jujutsu Kaisen*, here's an interesting mind twist I found: If we consider Kokichi Muta as GPT-4, would his end and motivations be the same as those of an AGI?
>
> I don't know the answer, but maybe you have some intriguing thoughts.

## Questions and Quasi-Answers

I often see people asking questions like these or similar:

* What counts as AI-native?
* Where is the boundary between model and application layers?
    * A more straightforward and boring translation would be: Where is OpenAI's boundary?

And a blog topic I previously considered was: Why is Rabbit R1 the new Zune?

When I recently put these questions and topics together on a table (in my mind), I suddenly realized that they all essentially ask the same thing:

**"What is the first principle of AI?"**

Once we understand or find the first principle of AI, the rest become much easier to address:

* Applications that follow the first principle of AI are AI-native. The abilities that directly extend from the AI's first principle are its native capabilities, which also means the boundaries of the model layer.
* Abilities that cannot be directly derived from the AI's first principle should be implemented at the application layer, which is the area OpenAI will not touch.
* Similarly, AI-native hardware follows the first principle of AI. Rabbit R1 is AI hardware based on old frames, metaphorically speaking: it's the new Zune.

> **What is a First Principle?**
>
> It seems everyone knows what a first principle is, as if it's something learned during high school. But it seems no one can clearly define a first principle. I don't know either (what they're talking about), so here's my understanding and definition:
>
> A first principle is, by logically deducing or deconstructing, tracing complex logic or combinations back to a few basic components. This tracing process involves continuously examining the necessity of various elements, then removing the unnecessary or derivative ones until what remains cannot be
> further divided.
> These indivisible basic components are the first principles. Or we could approximate them with "axioms" from first-order logic. We should teach first-order logic in high school instead of in graduate courses 🐶
>
> But what counts as "indivisible" or what constitutes "self-evident truth a.k.a. axioms"? That's a question!
>

## AI First Principles

TODO: Multimodal Intelligence

## Metadata

Version: 0.0.1

Date: 2024-02-19

License: [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)